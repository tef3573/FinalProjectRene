{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing USDA Food Data Central API for Nutritional Information\n",
    "\n",
    "This script interacts with the USDA Food Data Central API to search for food items and retrieve nutritional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDC ID: 770088, Description: OREO COOKIES\n",
      "\n",
      "Nutritional Information for OREO COOKIES:\n",
      "Carbohydrate, by difference: 73.0 g\n",
      "Total lipid (fat): 20.0 g\n",
      "Fiber, total dietary: 2.5 g\n",
      "Sodium, Na: 400.0 mg\n",
      "Total Sugars: 38.0 g\n",
      "Protein: 5.0 g\n",
      "Fatty acids, total saturated: 9.8 g\n"
     ]
    }
   ],
   "source": [
    "#!pip install requests\n",
    "import requests\n",
    "\n",
    "# Define your API key (it should be the actual key, not \"OAS3.0:\")\n",
    "api_key = 'M3175TAXsEcfdKkCOpNO9VcbwjQtFOkl9rUDAiaP'\n",
    "\n",
    "# Function to search for a food item and get its FDC ID\n",
    "def search_food(query):\n",
    "    #This is the data set for the USDA government\n",
    "    url = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
    "    # my parameters are query for the \n",
    "    params = {\n",
    "        \"query\": query, # search term enterd by user \n",
    "        \"api_key\": api_key, \n",
    "        \"pageSize\": 1  # Return only the top result\n",
    "    }\n",
    "    # using request.get() to send a get request to the API endpoint\n",
    "    response = requests.get(url, params=params)\n",
    "    #lines checks for the Https status and if it 200 then its okay\n",
    "    if response.status_code == 200:\n",
    "        # returns the json format to dictionary\n",
    "        data = response.json()\n",
    "        #checks for food items \n",
    "        if data['foods']:\n",
    "            # this will get the first result \n",
    "            food_item = data['foods'][0]\n",
    "            # return the food id and its description\n",
    "            return food_item['fdcId'], food_item['description']\n",
    "        else:\n",
    "           #No foods were found\n",
    "            print(\"No foods found.\")\n",
    "            return None, None\n",
    "    else:\n",
    "      # it will print out the error responce code\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to retrieve detailed nutritional information using FDC ID\n",
    "def get_food_details(fdc_id):\n",
    "\n",
    "    url = f\"https://api.nal.usda.gov/fdc/v1/food/{fdc_id}\"\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"format\": \"full\"#All available details for food\n",
    "    }\n",
    "    # Returns the full detail information for the food \n",
    "    response = requests.get(url, params=params)\n",
    "    # Same thing as earlier \n",
    "    if response.status_code == 200:\n",
    "        food_details = response.json()\n",
    "        return food_details\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# whatever the user wants\n",
    "\n",
    "foodname = str(input(\"Please enter the name of the object you want the nutrition data for: \"))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    food_query = foodname\n",
    "    fdc_id, description = search_food(food_query)\n",
    "    \n",
    "    if fdc_id:\n",
    "        print(f\"FDC ID: {fdc_id}, Description: {description}\")\n",
    "        food_details = get_food_details(fdc_id)\n",
    "        \n",
    "        # Print out some of the nutritional information\n",
    "        if food_details:\n",
    "            print(f\"\\nNutritional Information for {description}:\")\n",
    "            for nutrient in food_details.get('foodNutrients', []):\n",
    "                print(f\"{nutrient['nutrient']['name']}: {nutrient['amount']} {nutrient['nutrient']['unitName']}\")\n",
    "    else:\n",
    "        print(\"Could not retrieve food details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Video Frames in Smaller Batches\n",
    "\n",
    "1. Process multiple videos from the input folder.\n",
    "2. Create a new numbered subfolder within the output folder for each video.\n",
    "3. Name each subfolder with a sequential number followed by _vid.\n",
    "4. Store the extracted frames as JPG files within their respective subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def video_to_frames_in_smaller_batches(video_folder, output_folder, desired_fps):\n",
    "    print(f\"Processing videos in {video_folder} to {output_folder} with {desired_fps} FPS\")\n",
    "    # List all video files in the selected folder\n",
    "    video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f)) and f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "\n",
    "    if not video_files:\n",
    "        print(\"No video files found in the selected folder.\")\n",
    "        return\n",
    "\n",
    "    for idx, video_file in enumerate(video_files, start=1):\n",
    "        video_path = os.path.join(video_folder, video_file)\n",
    "\n",
    "        # Create a new subfolder in the output folder named <number>_vid\n",
    "        video_output_folder = os.path.join(output_folder, f'{idx}_vid')\n",
    "        os.makedirs(video_output_folder, exist_ok=True)\n",
    "\n",
    "        # Open the video file\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        if original_fps <= 0:\n",
    "            print(f\"Warning: Unable to retrieve FPS for video {video_file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Calculate the frame interval to match the desired FPS\n",
    "        frame_interval = int(round(original_fps / desired_fps))\n",
    "\n",
    "        if frame_interval <= 0:\n",
    "            frame_interval = 1  # Ensure at least every frame is processed\n",
    "\n",
    "        frame_count = 0\n",
    "        saved_frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Save frames at the specified interval into the specific subfolder\n",
    "            if frame_count % frame_interval == 0:\n",
    "                frame_filename = os.path.join(video_output_folder, f'frame_{saved_frame_count:05d}.jpg')\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "                saved_frame_count += 1\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Extracted frames from '{video_file}' into the folder '{video_output_folder}'.\")\n",
    "\n",
    "    print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video file selection\n",
    "\n",
    "This code cell creates a graphical user interface (GUI) using Python's `tkinter` library to assist users in processing video files. The GUI guides the user through the following steps:\n",
    "\n",
    "1. **Greeting the User**: Asks if they would like to process videos.\n",
    "2. **Selecting a Video Folder**: Opens a dialog for the user to choose a folder containing video files.\n",
    "3. **Handling Missing Files**: Provides help if the user cannot find the desired video folder.\n",
    "4. **Prompting for Frames Per Second (FPS)**: Asks the user to input the desired frames per second (FPS) for the video processing.\n",
    "5. **Selecting an Output Folder**: Prompts the user to choose or create a folder where the processed frames will be saved.\n",
    "6. **Handling Default Output Folder**: If the user does not select an output folder, the program creates a default folder named `output_file` in the current working directory.\n",
    "7. **Handling Duplicate Output Folders**: If a folder named `output_file` already exists, the program notifies the user and terminates to avoid conflicts.\n",
    "8. **Processing the Videos**: Processes the videos by extracting frames at the specified FPS and saves them in the output folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing videos in /Users/taneshafuller/Desktop/videofolder to /Users/taneshafuller/Desktop/output with 15 FPS\n",
      "Extracted frames from '6029299-hd_1920_1080_30fps.mp4' into the folder '/Users/taneshafuller/Desktop/output/1_vid'.\n",
      "Extracted frames from '5564265-hd_1920_1080_24fps.mp4' into the folder '/Users/taneshafuller/Desktop/output/2_vid'.\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, simpledialog\n",
    "\n",
    "\n",
    "# Function to handle when the user can't find their file (to be implemented)\n",
    "def handle_cant_find_file():\n",
    "    # Placeholder for the file search assistance logic\n",
    "    messagebox.showinfo(\"Help\", \"Please check your folder structure and try again.\")\n",
    "\n",
    "\n",
    "\n",
    "def greet_and_prompt():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "\n",
    "    # Greet the user\n",
    "    user_response = messagebox.askquestion(\"Welcome\", \"Hello! Would you like to process videos?\")\n",
    "\n",
    "    if user_response == 'yes':\n",
    "        while True:\n",
    "            # Ask the user to select the folder containing video files\n",
    "            video_folder = filedialog.askdirectory(title=\"Select the Folder Containing Videos\")\n",
    "\n",
    "            if video_folder:\n",
    "                break  # Break the loop if a folder is selected\n",
    "            else:\n",
    "                # Option for the user if they can't find the folder\n",
    "                cant_find_response = messagebox.askquestion(\"Can't Find Folder\",\n",
    "                                                            \"Can't find your folder? Would you like some help?\",\n",
    "                                                            icon='warning')\n",
    "                if cant_find_response == 'yes':\n",
    "                    handle_cant_find_file()\n",
    "                else:\n",
    "                    messagebox.showinfo(\"Goodbye\", \"You chose not to proceed. Goodbye!\")\n",
    "                    root.update()  # Process any pending events\n",
    "                    root.quit()  # Exit the main loop\n",
    "                    root.destroy()  # Destroy the Tkinter root window\n",
    "                    return  # Exit the function and stop the script\n",
    "\n",
    "        # Prompt the user to select the output folder\n",
    "        select_output_response = messagebox.askquestion(\"Output Folder\", \"Would you like to select an output folder now?\")\n",
    "        \n",
    "        if select_output_response == 'yes':\n",
    "            while True:\n",
    "                output_folder = filedialog.askdirectory(title=\"Select Output Folder\")\n",
    "\n",
    "                if output_folder:\n",
    "                    messagebox.showinfo(\"Folder Selected\", f\"Output folder selected: {output_folder}\")\n",
    "                    break  # Proceed if a valid output folder is selected\n",
    "                else:\n",
    "                    # Notify the user to select a folder or quit the process\n",
    "                    retry_response = messagebox.askquestion(\"No Folder Selected\",\n",
    "                                                            \"You haven't selected an output folder. Would you like to try again?\",\n",
    "                                                            icon='warning')\n",
    "                    if retry_response == 'no':\n",
    "                        messagebox.showinfo(\"Goodbye\", \"You chose not to proceed. Goodbye!\")\n",
    "                        root.update()  # Process any pending events\n",
    "                        root.quit()  # Exit the main loop\n",
    "                        root.destroy()  # Destroy the Tkinter root window\n",
    "                        return  # Exit the function and stop the script\n",
    "        else:\n",
    "            messagebox.showinfo(\"Goodbye\", \"You chose not to select an output folder. Goodbye!\")\n",
    "            root.update()  # Process any pending events\n",
    "            root.quit()  # Exit the main loop\n",
    "            root.destroy()  # Destroy the Tkinter root window\n",
    "            return  # Exit the function and stop the script\n",
    "\n",
    "        # Ask the user to input the frames per second (FPS)\n",
    "        fps = simpledialog.askinteger(\"Frames Per Second\", \"Please enter the frames per second (FPS) value:\", minvalue=1)\n",
    "\n",
    "        if fps:\n",
    "            # Call the function with the gathered information\n",
    "            video_to_frames_in_smaller_batches(video_folder, output_folder, int(fps))\n",
    "            messagebox.showinfo(\"Process Complete\", f\"Videos processed with {fps} frames per second.\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"No FPS Entered\", \"You didn't enter a valid FPS value. Goodbye!\")\n",
    "    \n",
    "    else:\n",
    "        messagebox.showinfo(\"Goodbye\", \"You chose not to proceed. Goodbye!\")\n",
    "    \n",
    "    root.update()  # Process any pending events\n",
    "    root.quit()  # Exit the main loop\n",
    "    root.destroy()  # Destroy the Tkinter root window\n",
    "\n",
    "\n",
    "# Call the function\n",
    "if __name__ == \"__main__\":\n",
    "    greet_and_prompt()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video segmentation with SAM 2\n",
    "This notebook shows how to use SAM 2 for interactive segmentation in videos. It will cover the following:\n",
    "\n",
    "- adding clicks (or box) on a frame to get and refine _masklets_ (spatio-temporal masks)\n",
    "- propagating clicks (or box) to get _masklets_ throughout the video\n",
    "- segmenting and tracking multiple objects at the same time\n",
    "\n",
    "We use the terms _segment_ or _mask_ to refer to the model prediction for an object on a single frame, and _masklet_ to refer to the spatio-temporal masks across the entire video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotating Images with Bounding Boxes for Object Detection\n",
    "\n",
    "This script helps annotate objects in images by drawing bounding boxes and saving them as training labels for models.\n",
    "If running locally using jupyter, first install `segment-anything-2` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything-2#installation) in the repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set env for SAM2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False\n",
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install opencv-python matplotlib\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything-2.git'\n",
    "\n",
    "    !mkdir -p videos\n",
    "    !wget -P videos https://dl.fbaipublicfiles.com/segment_anything_2/assets/bedroom.zip\n",
    "    !unzip -d videos videos/bedroom.zip\n",
    "\n",
    "    !mkdir -p ../checkpoints/\n",
    "    !wget -P ../checkpoints/ https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# if using Apple MPS, fall back to CPU for unsupported ops\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n",
      "\n",
      "Support for MPS devices is preliminary. SAM 2 is trained with CUDA and might give numerically different outputs and sometimes degraded performance on MPS. See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\n"
     ]
    }
   ],
   "source": [
    "# select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    # use bfloat16 for the entire notebook\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "elif device.type == \"mps\":\n",
    "    print(\n",
    "        \"\\nSupport for MPS devices is preliminary. SAM 2 is trained with CUDA and might \"\n",
    "        \"give numerically different outputs and sometimes degraded performance on MPS. \"\n",
    "        \"See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SAM2 Video Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "\n",
    "sam2_checkpoint = \"../checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, obj_id=None, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"tab10\")\n",
    "        cmap_idx = 0 if obj_id is None else obj_id\n",
    "        color = np.array([*cmap(cmap_idx)[:3], 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=200):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select an example video\n",
    "\n",
    "IT is assumend that the video is stored as a list of j peg frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directory: /Users/taneshafuller/Desktop/output/1_vid\n",
      "Final selected directory: /Users/taneshafuller/Desktop/output/1_vid\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "# Global variable to store the selected directory\n",
    "selected_directory = None\n",
    "\n",
    "# Function to pick a video directory\n",
    "def pick_directory():\n",
    "    global selected_directory\n",
    "    selected_directory = filedialog.askdirectory(title=\"Select Video Directory\")\n",
    "    if selected_directory:\n",
    "        label_var.set(f\"Stored Directory: {selected_directory}\")\n",
    "    else:\n",
    "        label_var.set(\"No directory/folder stored\")\n",
    "\n",
    "# Function to greet the user and provide instructions\n",
    "def greet_user():\n",
    "    messagebox.showinfo(\"Greeting\", \"Hello! Please select the video directory to store.\")\n",
    "\n",
    "# Function to perform some action with the selected directory\n",
    "def use_selected_directory():\n",
    "    if selected_directory:\n",
    "        print(f\"Using directory: {selected_directory}\")\n",
    "        # Here you can add the logic to use the selected directory\n",
    "    else:\n",
    "        print(\"No directory selected to use.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the Tkinter window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Video Directory Picker\")\n",
    "\n",
    "    # Greeting the user\n",
    "    greet_user()\n",
    "\n",
    "    # Label to display the stored directory or status\n",
    "    label_var = tk.StringVar()\n",
    "    label_var.set(\"No directory/folder stored\")\n",
    "\n",
    "    label = tk.Label(root, textvariable=label_var, font=(\"Arial\", 12))\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    # Button to open the directory picker\n",
    "    button = tk.Button(root, text=\"Pick Video Directory\", command=pick_directory, font=(\"Arial\", 12))\n",
    "    button.pack(pady=20)\n",
    "\n",
    "    # Button to use the selected directory in some way\n",
    "    use_button = tk.Button(root, text=\"Use Selected Directory\", command=use_selected_directory, font=(\"Arial\", 12))\n",
    "    use_button.pack(pady=20)\n",
    "\n",
    "    # Run the Tkinter event loop\n",
    "    root.mainloop()\n",
    "\n",
    "    # After the Tkinter loop ends, you can still access the selected_directory\n",
    "    if selected_directory:\n",
    "        print(f\"Final selected directory: {selected_directory}\")\n",
    "    else:\n",
    "        print(\"No directory was selected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renamed the file so it can be ordered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming completed. Files should now be in the correct format.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "video_dir = selected_directory\n",
    "\n",
    "# Scan all the JPEG frame names in this directory\n",
    "frame_names = [\n",
    "    p for p in os.listdir(video_dir)\n",
    "    if os.path.splitext(p)[-1].lower() in [\".jpg\", \".jpeg\"]\n",
    "]\n",
    "\n",
    "# Rename files by removing the 'frame_' prefix\n",
    "for frame_name in frame_names:\n",
    "    new_name = frame_name.replace('frame_', '')\n",
    "    os.rename(os.path.join(video_dir, frame_name), os.path.join(video_dir, new_name))\n",
    "\n",
    "print(\"Renaming completed. Files should now be in the correct format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the inference state\n",
    "Preparing SAM2 for performing task like video segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame loading (JPEG): 100%|██████████| 115/115 [00:05<00:00, 21.73it/s]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/functional.py:4095: UserWarning: The operator 'aten::upsample_bicubic2d.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)\n"
     ]
    }
   ],
   "source": [
    "inference_state = predictor.init_state(video_path=video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Segment & track one object\n",
    "\n",
    "Note: if you have run any previous tracking using this `inference_state`, please reset it first via `reset_state`.\n",
    "\n",
    "(The cell below is just for illustration; it's not needed to call `reset_state` here as this `inference_state` is just freshly initialized above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.reset_state(inference_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Add a first click on a frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/taneshafuller/Desktop/output/1_vid\n"
     ]
    }
   ],
   "source": [
    "print(selected_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing users coordinates for object selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked coordinates: [(357, 253)]\n",
      "Clicked coordinates: [(357, 253), (493, 195)]\n",
      "Clicked coordinates: [(357, 253), (493, 195), (435, 272)]\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "\n",
    "# Initialize the global coordinates variable\n",
    "coordinates = []\n",
    "\n",
    "# Function to access the first jpg frame of the video folder\n",
    "def access_first_frame(video_dir):\n",
    "    files = [f for f in os.listdir(video_dir) if f.endswith('.jpg')]\n",
    "    if not files:\n",
    "        print(\"No JPG files found in the directory.\")\n",
    "        return None\n",
    "    first_frame_path = os.path.join(video_dir, files[0])\n",
    "    return first_frame_path\n",
    "\n",
    "\n",
    "\n",
    "# Function to handle single clicks (adding or removing a coordinate)\n",
    "def on_single_click(event, canvas):\n",
    "    global coordinates  # Declare that we are using the global coordinates list\n",
    "    x, y = event.x, event.y\n",
    "    clicked_coord = (x, y)\n",
    "\n",
    "    # Check if the click is near an existing coordinate to remove it\n",
    "    for coord in coordinates:\n",
    "        if abs(coord[0] - x) <= 5 and abs(coord[1] - y) <= 5:\n",
    "            coordinates.remove(coord)\n",
    "            print(f\"Removed coordinates: {coord}\")\n",
    "            display_image(canvas.video_dir, canvas)\n",
    "            return\n",
    "    \n",
    "    # If the click is not on an existing dot, add the coordinate\n",
    "    coordinates.append(clicked_coord)\n",
    "    print(f\"Clicked coordinates: {coordinates}\")\n",
    "    # Mark the coordinate on the canvas\n",
    "    canvas.create_oval(x-5, y-5, x+5, y+5, outline=\"red\", width=2)\n",
    "\n",
    "# Function to display the first frame on the canvas\n",
    "def display_image(video_dir, canvas):\n",
    "    first_frame_path = access_first_frame(video_dir)\n",
    "    if not first_frame_path:\n",
    "        return\n",
    "\n",
    "    img = Image.open(first_frame_path)\n",
    "    img.thumbnail((800, 600))  # Adjust thumbnail size as needed\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "    canvas.delete(\"all\")\n",
    "    canvas.image = img_tk  # Keep a reference to avoid garbage collection\n",
    "    canvas.create_image(0, 0, anchor=tk.NW, image=img_tk)\n",
    "\n",
    "    # Redraw existing coordinates on the image\n",
    "    for coord in coordinates:\n",
    "        canvas.create_oval(coord[0]-5, coord[1]-5, coord[0]+5, coord[1]+5, outline=\"red\", width=2)\n",
    "\n",
    "# Main function to set up the GUI\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Image Clicker\")\n",
    "\n",
    "    # Use the pre-defined directory containing JPG files\n",
    "    video_dir = selected_directory\n",
    "    if not video_dir:\n",
    "        print(\"No directory selected.\")\n",
    "        return\n",
    "\n",
    "    canvas = tk.Canvas(root, width=800, height=600)\n",
    "    canvas.pack()\n",
    "\n",
    "    # Store the directory path in the canvas object\n",
    "    canvas.video_dir = video_dir\n",
    "\n",
    "    # Bind single-click (Button-1) to add or remove a coordinate\n",
    "    canvas.bind(\"<Button-1>\", lambda event: on_single_click(event, canvas))\n",
    "\n",
    "    display_image(video_dir, canvas)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final coordinates after GUI closes: [(357, 253), (493, 195), (435, 272)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final coordinates after GUI closes:\", coordinates)\n",
    "first_frame =  access_first_frame(selected_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n"
     ]
    }
   ],
   "source": [
    "print(coordinates[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEre is the func i want you to look at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle single clicks (adding or removing a coordinate)\n",
    "def on_single_click(event, canvas):\n",
    "    global coordinates, original_size  # Declare that we are using the global coordinates list\n",
    "    x, y = event.x, event.y\n",
    "\n",
    "    # Get the canvas size\n",
    "    canvas_width = canvas.winfo_width()\n",
    "    canvas_height = canvas.winfo_height()\n",
    "\n",
    "    # Adjust coordinates based on the scale of the image\n",
    "    scale_x = original_size[0] / canvas_width\n",
    "    scale_y = original_size[1] / canvas_height\n",
    "\n",
    "    # Transform the click coordinates to match the original image size\n",
    "    transformed_x = x * scale_x\n",
    "    transformed_y = y * scale_y\n",
    "    clicked_coord = (transformed_x, transformed_y)\n",
    "\n",
    "    # Check if the click is near an existing coordinate to remove it\n",
    "    for coord in coordinates:\n",
    "        if abs(coord[0] - transformed_x) <= 5 * scale_x and abs(coord[1] - transformed_y) <= 5 * scale_y:\n",
    "            coordinates.remove(coord)\n",
    "            print(f\"Removed coordinates: {coord}\")\n",
    "            display_image(canvas.video_dir, canvas)\n",
    "            update_segmentation(canvas)  # Update the segmentation after removing a point\n",
    "            return\n",
    "    \n",
    "    # If the click is not on an existing dot, add the coordinate\n",
    "    coordinates.append(clicked_coord)\n",
    "    print(f\"Clicked coordinates: {coordinates}\")\n",
    "    # Mark the coordinate on the canvas\n",
    "    canvas.create_oval(x-5, y-5, x+5, y+5, outline=\"red\", width=2)\n",
    "    update_segmentation(canvas)  # Update the segmentation after adding a point\n",
    "\n",
    "# Function to display the first frame on the canvas\n",
    "def display_image(video_dir, canvas):\n",
    "    global original_size\n",
    "    first_frame_path = access_first_frame(video_dir)\n",
    "    if not first_frame_path:\n",
    "        return\n",
    "\n",
    "    img = Image.open(first_frame_path)\n",
    "    original_size = img.size  # Store the original image size before resizing\n",
    "\n",
    "    # Resize the image while maintaining the aspect ratio to fit within the canvas\n",
    "    img.thumbnail((canvas.winfo_width(), canvas.winfo_height()), Image.ANTIALIAS)\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "    canvas.delete(\"all\")\n",
    "    canvas.image = img_tk  # Keep a reference to avoid garbage collection\n",
    "    canvas.create_image(0, 0, anchor=tk.NW, image=img_tk)\n",
    "\n",
    "    # Redraw existing coordinates on the image\n",
    "    for coord in coordinates:\n",
    "        # Reverse scaling to map the coordinates to the canvas size\n",
    "        scaled_x = coord[0] / original_size[0] * canvas.winfo_width()\n",
    "        scaled_y = coord[1] / original_size[1] * canvas.winfo_height()\n",
    "        canvas.create_oval(scaled_x-5, scaled_y-5, scaled_x+5, scaled_y+5, outline=\"red\", width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "image \"pyimage5\" doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 143\u001b[0m\n\u001b[1;32m    139\u001b[0m     display_image(video_dir, canvas)\n\u001b[1;32m    141\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m--> 143\u001b[0m main()\n",
      "Cell \u001b[0;32mIn[27], line 139\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m canvas\u001b[38;5;241m.\u001b[39mvideo_dir \u001b[38;5;241m=\u001b[39m video_dir\n\u001b[1;32m    137\u001b[0m canvas\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Button-1>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m event: on_single_click(event, canvas))\n\u001b[0;32m--> 139\u001b[0m display_image(video_dir, canvas)\n\u001b[1;32m    141\u001b[0m root\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[0;32mIn[27], line 78\u001b[0m, in \u001b[0;36mdisplay_image\u001b[0;34m(video_dir, canvas)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Store the image object in the canvas itself to prevent garbage collection\u001b[39;00m\n\u001b[1;32m     77\u001b[0m canvas\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m img_tk  \n\u001b[0;32m---> 78\u001b[0m canvas\u001b[38;5;241m.\u001b[39mcreate_image(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, anchor\u001b[38;5;241m=\u001b[39mtk\u001b[38;5;241m.\u001b[39mNW, image\u001b[38;5;241m=\u001b[39mimg_tk)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Redraw existing coordinates on the image\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m coordinates:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/tkinter/__init__.py:2875\u001b[0m, in \u001b[0;36mCanvas.create_image\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m   2873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m   2874\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create image item with coordinates x1,y1.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, args, kw)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/tkinter/__init__.py:2861\u001b[0m, in \u001b[0;36mCanvas._create\u001b[0;34m(self, itemType, args, kw)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2860\u001b[0m     cnf \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 2861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk\u001b[38;5;241m.\u001b[39mgetint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m   2862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate\u001b[39m\u001b[38;5;124m'\u001b[39m, itemType,\n\u001b[1;32m   2863\u001b[0m     \u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options(cnf, kw))))\n",
      "\u001b[0;31mTclError\u001b[0m: image \"pyimage5\" doesn't exist"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "# Global variables\n",
    "coordinates = []  # Store the coordinates clicked by the user\n",
    "original_size = None  # Store the original size of the image\n",
    "\n",
    "# Function to extract the frame index from the frame path\n",
    "def extract_frame_index(frame_path):\n",
    "    base_name = os.path.basename(frame_path)\n",
    "    frame_index = int(os.path.splitext(base_name)[0])\n",
    "    return frame_index\n",
    "\n",
    "# Function to access the first jpg frame of the video folder\n",
    "def access_first_frame(video_dir):\n",
    "    files = [f for f in os.listdir(video_dir) if f.endswith('.jpg')]\n",
    "    if not files:\n",
    "        print(\"No JPG files found in the directory.\")\n",
    "        return None\n",
    "    first_frame_path = os.path.join(video_dir, files[0])\n",
    "    return first_frame_path\n",
    "\n",
    "# Function to handle single clicks (adding or removing a coordinate)\n",
    "def on_single_click(event, canvas):\n",
    "    global coordinates, original_size\n",
    "    x, y = event.x, event.y\n",
    "\n",
    "    # Get the canvas size\n",
    "    canvas_width = canvas.winfo_width()\n",
    "    canvas_height = canvas.winfo_height()\n",
    "\n",
    "    # Adjust coordinates based on the scale of the image\n",
    "    scale_x = original_size[0] / canvas_width\n",
    "    scale_y = original_size[1] / canvas_height\n",
    "\n",
    "    # Transform the click coordinates to match the original image size\n",
    "    transformed_x = x * scale_x\n",
    "    transformed_y = y * scale_y\n",
    "    clicked_coord = (transformed_x, transformed_y)\n",
    "\n",
    "    # Check if the click is near an existing coordinate to remove it\n",
    "    for coord in coordinates:\n",
    "        if abs(coord[0] - transformed_x) <= 5 * scale_x and abs(coord[1] - transformed_y) <= 5 * scale_y:\n",
    "            coordinates.remove(coord)\n",
    "            print(f\"Removed coordinates: {coord}\")\n",
    "            display_image(canvas.video_dir, canvas)\n",
    "            update_segmentation(canvas)\n",
    "            return\n",
    "    \n",
    "    # If the click is not on an existing dot, add the coordinate\n",
    "    coordinates.append(clicked_coord)\n",
    "    print(f\"Clicked coordinates: {coordinates}\")\n",
    "    canvas.create_oval(x-5, y-5, x+5, y+5, outline=\"red\", width=2)\n",
    "    update_segmentation(canvas)\n",
    "\n",
    "# Function to display the first frame on the canvas\n",
    "def display_image(video_dir, canvas):\n",
    "    global original_size\n",
    "    first_frame_path = access_first_frame(video_dir)\n",
    "    if not first_frame_path:\n",
    "        return\n",
    "\n",
    "    img = Image.open(first_frame_path)\n",
    "    original_size = img.size  # Store the original image size before resizing\n",
    "\n",
    "    # Resize the image while maintaining the aspect ratio to fit within the canvas\n",
    "    img.thumbnail((canvas.winfo_width(), canvas.winfo_height()), Image.Resampling.LANCZOS)\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "    canvas.delete(\"all\")\n",
    "    \n",
    "    # Store the image object in the canvas itself to prevent garbage collection\n",
    "    canvas.image = img_tk  \n",
    "    canvas.create_image(0, 0, anchor=tk.NW, image=img_tk)\n",
    "\n",
    "    # Redraw existing coordinates on the image\n",
    "    for coord in coordinates:\n",
    "        scaled_x = coord[0] / original_size[0] * canvas.winfo_width()\n",
    "        scaled_y = coord[1] / original_size[1] * canvas.winfo_height()\n",
    "        canvas.create_oval(scaled_x-5, scaled_y-5, scaled_x+5, scaled_y+5, outline=\"red\", width=2)\n",
    "\n",
    "# Function to generate a unique object ID\n",
    "def generate_unique_obj_id(points):\n",
    "    return hash(tuple(points.flatten()))\n",
    "\n",
    "# Function to update segmentation based on the clicked points\n",
    "def update_segmentation(canvas):\n",
    "    points = np.array([[coord[0], coord[1]] for coord in coordinates], dtype=np.float32)\n",
    "    labels = np.ones(len(coordinates), dtype=np.int32)\n",
    "\n",
    "    frame_path = access_first_frame(canvas.video_dir)\n",
    "\n",
    "    mask, frame_path = segment_object(frame_path, points, labels)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.imshow(Image.open(frame_path))\n",
    "    plt.imshow(mask, alpha=0.5, cmap='jet')\n",
    "    plt.scatter(points[:, 0], points[:, 1], color='gold', marker='*', s=200)\n",
    "    plt.title(\"Segmentation Result\")\n",
    "    plt.show()\n",
    "\n",
    "# Function to handle segmentation (replace with your model logic)\n",
    "def segment_object(frame_path, points, labels, obj_id=None):\n",
    "    img = Image.open(frame_path)\n",
    "    mask = np.zeros((img.height, img.width))\n",
    "    return mask, frame_path\n",
    "\n",
    "# Function to select the directory dynamically\n",
    "def select_directory():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    selected_directory = filedialog.askdirectory(title=\"Select Directory with Video Frames\")\n",
    "    return selected_directory\n",
    "\n",
    "# Main function to set up the GUI and run the app\n",
    "def main():\n",
    "    video_dir = select_directory()\n",
    "\n",
    "    if not video_dir:\n",
    "        print(\"No directory selected.\")\n",
    "        return\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Image Clicker\")\n",
    "\n",
    "    canvas = tk.Canvas(root, width=800, height=600)\n",
    "    canvas.pack()\n",
    "\n",
    "    canvas.video_dir = video_dir\n",
    "\n",
    "    canvas.bind(\"<Button-1>\", lambda event: on_single_click(event, canvas))\n",
    "\n",
    "    display_image(video_dir, canvas)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
